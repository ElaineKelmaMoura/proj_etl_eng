# Projeto ETL - Engenharia de Dados

## ğŸ“Œ Objetivo

Implementar um pipeline de dados distribuÃ­do utilizando Docker, Kafka e Spark,
processando dados financeiros e armazenando em camadas no Amazon S3.

---

## ğŸ—  Arquitetura Atual (Infraestrutura + Bronze)

Fluxo de dados:

PostgreSQL â†’ Kafka â†’ Kafka Connect â†’ Amazon S3 (Bronze) â†’ Apache Spark


            +-------------+
            | PostgreSQL  |
            +-------------+
                    |
                    v
            +-------------+
            |   Kafka     |
            +-------------+
                    |
                    v
            +-----------------+
            | Kafka Connect   |
            +-----------------+
                    |
                    v
            +-------------+
            |  AWS S3     |
            |  (Bronze)   |
            +-------------+
                    |
                    v
            +-------------+
            |  Apache     |
            |   Spark     |
            +-------------+

---

## âš™ï¸ Stack Utilizada

- Docker & Docker Compose
- PostgreSQL
- Apache Kafka
- Kafka Connect
- AWS S3
- Apache Spark (Master + Worker)
- Jupyter Lab
- Python (PySpark)

---

## ğŸ“‚ Estrutura do Projeto


---

## ğŸ“ˆ Resultados Obtidos

- Cluster Spark distribuÃ­do funcionando
- Kafka Connect enviando dados para S3
- Estrutura Bronze armazenando dados em JSON
- Ambiente totalmente containerizado

---
